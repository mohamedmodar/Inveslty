{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10969691,"sourceType":"datasetVersion","datasetId":6825480},{"sourceId":10992966,"sourceType":"datasetVersion","datasetId":6842522},{"sourceId":11039975,"sourceType":"datasetVersion","datasetId":6876594},{"sourceId":11050286,"sourceType":"datasetVersion","datasetId":6884141},{"sourceId":11077938,"sourceType":"datasetVersion","datasetId":6904443},{"sourceId":11116993,"sourceType":"datasetVersion","datasetId":6931822},{"sourceId":11120439,"sourceType":"datasetVersion","datasetId":6934512}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.decomposition import PCA\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.linear_model import LassoCV\nimport pandas as pd\nimport numpy as np\nimport warnings\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import TimeSeriesSplit, GridSearchCV\nfrom joblib import parallel_backend\nfrom tqdm import tqdm\nimport time\nfrom sklearn.utils import resample\nwarnings.filterwarnings(\"ignore\")\n\ndef import_data():\n    macro = pd.read_csv(\"/kaggle/input/boost-data/macroeconomics.csv\", index_col=0)\n    # areas_prices = pd.read_csv(\"/kaggle/input/ppm-v2/ppm_2017_2024_areas_final_v2.csv\", index_col=0)\n    areas_prices = pd.read_csv(\"/kaggle/input/boost-data/price_per_meter_2017_2024_v2.csv\", index_col=0)\n\n    areas = areas_prices.columns\n    area = areas[area_num]\n    areas_prices = areas_prices.reset_index()\n    areas_prices = areas_prices[[area, \"Date\"]]\n    # areas_prices = areas_prices.melt(id_vars='Date', var_name='Area', value_name='Price Per Meter')\n    \n    alex = pd.merge(macro, areas_prices, on=\"Date\", how=\"left\")\n    # alex = alex.drop([\"Area\"], axis=1)\n    alex = alex.dropna(subset=['Price Per Meter'])\n    alex = alex.drop([\"Alexandria's Real Estate Ownership (GDP) (Thousands EGP)\"], axis=1)\n    alex['Year'] = alex['Date'].str[:4]  \n    alex['Quarter'] = alex['Date'].str[5:].astype(int)\n    alex = alex.drop_duplicates(subset=[\"Date\"]).reset_index(drop=True)\n    \n    og_columns = list(alex.columns)\n    \n    alex.attrs['area'] = area\n\n    return alex\n\ndef select_lags(alex, lags_n):\n    lags = {}\n    for col in alex.columns:\n        if col in [\"Date\", \"Year\", \"Quarter\", \"Price Per Meter\"]:\n            continue\n    \n        for i in range(1,lags_n):\n            lag = col + \"_lag_\" + str(i)\n            lags[lag] = alex[col].shift(i)\n            \n    lags_df = pd.concat(lags, axis=1)\n    \n    X = lags_df\n    X.fillna(0, inplace=True)\n    y = alex['Price Per Meter']\n    \n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n    \n    tscv = TimeSeriesSplit(n_splits=5)\n    \n    lasso = LassoCV(cv=tscv)\n    lasso.fit(X_scaled, y)\n    \n    coef = pd.Series(lasso.coef_, index=X.columns)\n    selected_lags = coef[coef != 0].index.tolist()\n\n    lags_df = lags_df.drop(columns=[col for col in lags_df.columns if col not in selected_lags], axis=1)\n    alex = pd.concat([alex, lags_df], axis=1)\n    alex.set_index(\"Date\", inplace=True)\n\n    return alex\n\ndef data_preprocessing(alex, pca_comp, tst_size):\n    # alex[\"Price Per Meter\"] = np.log1p(alex[\"Price Per Meter\"])\n    # alex[\"Price Per Meter\"] = alex[\"Price Per Meter\"] - alex[\"Price Per Meter\"].shift(1)\n    # alex = alex.dropna(subset=['Price Per Meter'])\n    X = alex.drop([\"Price Per Meter\"], axis=1)\n    y = alex[\"Price Per Meter\"]\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=tst_size, shuffle=False)\n    y_train = np.reshape(y_train, (y_train.shape[0], 1))\n    y_test = np.reshape(y_test, (y_test.shape[0], 1))\n\n    X_train = create_pca_comp(X_train, pca_comp)\n    X_test = create_pca_comp(X_test, pca_comp)\n    \n    X_train[\"Quarter\"] = X_train[\"Quarter\"].astype(int)\n    X_test[\"Quarter\"] = X_test[\"Quarter\"].astype(int)\n    X_test[\"Year\"] = X_test[\"Year\"].astype(int)\n    X_train[\"Year\"] = X_train[\"Year\"].astype(int)\n\n    return (X_train, X_test, y_train, y_test)\n\ndef create_pca_comp(X, pca_comp):\n    date = X[['Year', 'Quarter']]\n    pca = PCA(n_components=pca_comp)\n    X.fillna(0, inplace=True)\n    X_pca = pca.fit_transform(X.drop([\"Year\", \"Quarter\"], axis=1))\n    \n    df_pca = pd.DataFrame(X_pca, columns=[f'pca_{i+1}' for i in range(X_pca.shape[1])])\n    X = pd.concat([date.reset_index(drop=True), df_pca], axis=1)\n    \n    X.replace(0, np.nan, inplace=True)\n\n    return X\n\ndef scale_data(X_train, X_test, y_train, y_test):\n    x_scaler = MinMaxScaler()\n\n    X_train = pd.DataFrame(x_scaler.fit_transform(X_train), \n                         columns=X_train.columns, \n                         index=X_train.index)\n    \n    X_test = pd.DataFrame(x_scaler.fit_transform(X_test), \n                         columns=X_test.columns, \n                         index=X_test.index)\n    \n    y_scaler = MinMaxScaler()\n    \n    y_test = y_scaler.fit_transform(y_test)\n    \n    y_train = y_scaler.fit_transform(y_train)\n\n    return (X_train, X_test, y_train, y_test, x_scaler, y_scaler)\n\ndef select_best_model_params(X_train, y_train):\n    cv_split = TimeSeriesSplit(n_splits=4)\n    model = xgb.XGBRegressor()\n    parameters = {\n        \"max_depth\": [3, 4, 5, 7],\n        \"learning_rate\": [0.01, 0.05, 0.1, 0.2, 0.3],\n        \"n_estimators\": [10, 30, 50, 100, 200],\n    }\n\n    # 'reg_alpha': [0, 0.1, 0.5],\n    #     'reg_lambda': [0, 0.1, 0.5]\n    \n    grid_search = GridSearchCV(estimator=model, cv=cv_split, param_grid=parameters, scoring='r2', verbose=1)\n    grid_search.fit(X_train, y_train)\n    return grid_search.best_params_\n\ndef get_params(itrs):\n    sorted_itrs = sorted(itrs, key=lambda x: x['R2'], reverse=True)\n    params = sorted_itrs[0]\n    return params\n\ndef run_model(X_train, X_test, y_train, y_test, best_model_params):\n    reg = xgb.XGBRegressor(base_score=0.5, booster='gbtree',    \n                           n_estimators=best_model_params[\"n_estimators\"],\n                           early_stopping_rounds=10,\n                           objective='reg:squarederror',\n                           max_depth=best_model_params[\"max_depth\"],\n                           learning_rate=best_model_params[\"learning_rate\"], \n                           random_state=42, \n                           subsample=1.0, \n                           reg_alpha=0,\n                           colsample_bytree=0.7, \n                           reg_lambda=0.5,\n                           seed=25)\n    \n    reg.fit(X_train, y_train,\n            eval_set=[(X_train, y_train), (X_test, y_test)],\n            verbose=False)\n\n    pred = reg.predict(X_test)\n    r2 = r2_score(y_test, pred)\n    \n    return (r2, reg)    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T22:14:57.857751Z","iopub.execute_input":"2025-03-21T22:14:57.858190Z","iopub.status.idle":"2025-03-21T22:14:57.882993Z","shell.execute_reply.started":"2025-03-21T22:14:57.858158Z","shell.execute_reply":"2025-03-21T22:14:57.880958Z"}},"outputs":[],"execution_count":140},{"cell_type":"code","source":"def get_future_data(params):\n    macro_test = pd.read_csv(\"/kaggle/input/macro-2025-2028/macro_pred_2025_2028.csv\", index_col=0)\n    \n    macro_test.index.name = \"Date\"\n    \n    macro_test = macro_test.rename(columns={\"Real Estate Activitie\":\"Egypt's Real Estate Activities (GDP) (Millions EGP)\",\n                              \"Points\":\"Aqarmap Index\"})\n    \n    macro_test_lags = {}\n    for col in macro_test.columns:\n        for i in range(1, params[\"LAGS\"]):\n            lag = col + \"_lag_\" + str(i)\n            macro_test_lags[lag] = macro_test[col].shift(i)\n            \n    macro_test_lags_df = pd.concat(macro_test_lags, axis=1)\n    \n    macro_test = pd.concat([macro_test, macro_test_lags_df], axis=1)\n    \n    macro_test['Year'] = macro_test.index.str[:4].astype(int)\n    macro_test['Quarter'] = macro_test.index.str[5:].astype(int)\n    \n    macro_test.fillna(0, inplace=True)\n    \n    pca = PCA(n_components=params[\"PCA\"])\n    macro_test_pca = pca.fit_transform(macro_test.drop([\"Year\", \"Quarter\"], axis=1))\n    \n    df_pca = pd.DataFrame(macro_test_pca, columns=[f'pca_{i+1}' for i in range(macro_test_pca.shape[1])])\n    macro_test_pca = pd.concat([macro_test[['Year', 'Quarter']].reset_index(drop=True), df_pca], axis=1)\n    \n    macro_test_pca.replace(0, np.nan, inplace=True)\n    \n    macro_test_pca = pd.DataFrame(x_scaler.fit_transform(macro_test_pca), \n                         columns=macro_test_pca.columns, \n                         index=macro_test_pca.index)\n\n    return (macro_test_pca, macro_test)\n    \ndef run_model_ci(X_train, X_test, y_train, y_test, best_model_params, future_data):\n    n_bootstraps = 1000\n    preds_bootstrap = []\n    \n    for i in range(n_bootstraps):\n        X_resampled, y_resampled = resample(X_train, y_train, replace=True, random_state=i)\n        \n        model = xgb.XGBRegressor(base_score=0.5, booster='gbtree',    \n                           n_estimators=best_model_params[\"n_estimators\"],\n                           objective='reg:squarederror',\n                           max_depth=best_model_params[\"max_depth\"],\n                           learning_rate=best_model_params[\"learning_rate\"], \n                           random_state=42, \n                           subsample=1.0, \n                           reg_alpha=0,\n                           colsample_bytree=0.7, \n                           reg_lambda=0.5,\n                           seed=25)\n        \n        model.fit(X_resampled, y_resampled)\n        \n        preds = model.predict(future_data)\n        preds_bootstrap.append(y_scaler.inverse_transform([preds]))\n    \n    preds_bootstrap = np.array(preds_bootstrap)\n    \n    mean_preds = preds_bootstrap.mean(axis=0)\n    std_preds = preds_bootstrap.std(axis=0)\n\n    lower_bound = mean_preds - 1.44 * std_preds\n    upper_bound = mean_preds + 1.44 * std_preds\n\n    return (lower_bound, upper_bound, mean_preds)\n\ndef get_ci(X_train, X_test, y_train, y_test, best_model_params, future_data_pca):\n    (lower_bound, upper_bound, means_preds) = run_model_ci(X_train, X_test, y_train, y_test, best_model_params, future_data_pca)\n    means_preds, lower_bound, upper_bound = means_preds.flatten() * 2.43, lower_bound.flatten() * 2.43, upper_bound.flatten() * 2.43\n    return (lower_bound, upper_bound, means_preds)\n\ndef get_ci_chart(lower_bound, upper_bound, means_preds, area, q_labels):\n    plt.plot(means_preds, label='Mean Prediction')\n    plt.xticks(ticks=range(len(means_preds)), labels=q_labels, rotation=30) \n    plt.fill_between(range(len(means_preds)), lower_bound, upper_bound, alpha=0.3, label='Confidence Interval')\n    plt.title(area)\n    plt.legend()\n    chart_title = area + \"-forecast.png\"\n    plt.savefig(chart_title, dpi=300, bbox_inches='tight')\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T22:11:47.561302Z","iopub.execute_input":"2025-03-21T22:11:47.561677Z","iopub.status.idle":"2025-03-21T22:11:47.577579Z","shell.execute_reply.started":"2025-03-21T22:11:47.561647Z","shell.execute_reply":"2025-03-21T22:11:47.575861Z"}},"outputs":[],"execution_count":132},{"cell_type":"code","source":"import time\nstart_time = time.time()\n\narea_num = 0\nitrs = []\nfor size in np.arange(0.05, 0.25, 0.05):\n    for i in range(4, 21, 4):\n        alex = import_data()\n        alex = select_lags(alex, i)\n        print(alex.attrs['area'])\n        loop_pca_untill = int(size * alex.shape[0]) + 1\n        for comp in range(5, loop_pca_untill):\n            print(\"----------------------\")\n            (X_train, X_test, y_train, y_test) = data_preprocessing(alex, comp, size)\n            (X_train, X_test, y_train, y_test, x_scaler, y_scaler) = scale_data(X_train, X_test, y_train, y_test)\n            \n            # if len(best_model_params) == 0:\n            print(\"Getting best model parameters\")\n            best_model_params = select_best_model_params(X_train, y_train)\n            print(best_model_params)\n            (r2, reg) = run_model(X_train, X_test, y_train, y_test, best_model_params)\n    \n            itrs.append({\"Test-Size\": size, \"LAGS\": i, \"PCA\": comp, \"R2\": r2} | best_model_params)\n            print(\"Test-Size=\" + str(size) + \" - LAGS=\" + str(i) + \" - PCA=\" + str(comp) + \" - R2=\" + str(r2))\n        print(\"----------------------\\n\")\n\nend_time = time.time()\nelapsed_time = end_time - start_time\nminutes = int(elapsed_time // 60)\nseconds = int(elapsed_time % 60)\nduration = str(minutes) + \":\" + str(seconds)\nprint(\"\\nTime to find best params = \" + duration)\n\nparams = get_params(itrs)\nprint(\"Best params : \" + str(params))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T22:15:07.820412Z","iopub.execute_input":"2025-03-21T22:15:07.820766Z","iopub.status.idle":"2025-03-21T22:17:25.715667Z","shell.execute_reply.started":"2025-03-21T22:15:07.820740Z","shell.execute_reply":"2025-03-21T22:17:25.714711Z"}},"outputs":[{"name":"stdout","text":"Price Per Meter\n----------------------\n\nPrice Per Meter\n----------------------\n\nPrice Per Meter\n----------------------\n\nPrice Per Meter\n----------------------\n\nPrice Per Meter\n----------------------\n\nPrice Per Meter\n----------------------\n\nPrice Per Meter\n----------------------\n\nPrice Per Meter\n----------------------\n\nPrice Per Meter\n----------------------\n\nPrice Per Meter\n----------------------\n\nPrice Per Meter\n----------------------\n\nPrice Per Meter\n----------------------\n\nPrice Per Meter\n----------------------\n\nPrice Per Meter\n----------------------\n\nPrice Per Meter\n----------------------\n\nPrice Per Meter\n----------------------\nGetting best model parameters\nFitting 4 folds for each of 100 candidates, totalling 400 fits\n{'learning_rate': 0.3, 'max_depth': 7, 'n_estimators': 50}\nTest-Size=0.2 - LAGS=4 - PCA=5 - R2=-0.30867744734795366\n----------------------\nGetting best model parameters\nFitting 4 folds for each of 100 candidates, totalling 400 fits\n{'learning_rate': 0.3, 'max_depth': 4, 'n_estimators': 50}\nTest-Size=0.2 - LAGS=4 - PCA=6 - R2=0.4941194688071735\n----------------------\n\nPrice Per Meter\n----------------------\nGetting best model parameters\nFitting 4 folds for each of 100 candidates, totalling 400 fits\n{'learning_rate': 0.3, 'max_depth': 4, 'n_estimators': 100}\nTest-Size=0.2 - LAGS=8 - PCA=5 - R2=0.2646987799674736\n----------------------\nGetting best model parameters\nFitting 4 folds for each of 100 candidates, totalling 400 fits\n{'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 50}\nTest-Size=0.2 - LAGS=8 - PCA=6 - R2=0.40726782514268256\n----------------------\n\nPrice Per Meter\n----------------------\nGetting best model parameters\nFitting 4 folds for each of 100 candidates, totalling 400 fits\n{'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 100}\nTest-Size=0.2 - LAGS=12 - PCA=5 - R2=0.6075230551198473\n----------------------\nGetting best model parameters\nFitting 4 folds for each of 100 candidates, totalling 400 fits\n{'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 100}\nTest-Size=0.2 - LAGS=12 - PCA=6 - R2=0.3996521365970702\n----------------------\n\nPrice Per Meter\n----------------------\nGetting best model parameters\nFitting 4 folds for each of 100 candidates, totalling 400 fits\n{'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 100}\nTest-Size=0.2 - LAGS=16 - PCA=5 - R2=0.007007940529079715\n----------------------\nGetting best model parameters\nFitting 4 folds for each of 100 candidates, totalling 400 fits\n{'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 100}\nTest-Size=0.2 - LAGS=16 - PCA=6 - R2=0.37800267198555526\n----------------------\n\nPrice Per Meter\n----------------------\nGetting best model parameters\nFitting 4 folds for each of 100 candidates, totalling 400 fits\n{'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 100}\nTest-Size=0.2 - LAGS=20 - PCA=5 - R2=0.3877511277073715\n----------------------\nGetting best model parameters\nFitting 4 folds for each of 100 candidates, totalling 400 fits\n{'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 100}\nTest-Size=0.2 - LAGS=20 - PCA=6 - R2=0.6311944888978861\n----------------------\n\n\nTime to find best params = 2:17\nBest params : {'Test-Size': 0.2, 'LAGS': 20, 'PCA': 6, 'R2': 0.6311944888978861, 'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 100}\n","output_type":"stream"}],"execution_count":141},{"cell_type":"code","source":"params","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T21:51:01.955512Z","iopub.status.idle":"2025-03-21T21:51:01.955880Z","shell.execute_reply":"2025-03-21T21:51:01.955714Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"(future_data_pca, future_data) = get_future_data(params)\n\nalex = import_data()\nalex = select_lags(alex, params[\"LAGS\"])\n(X_train, X_test, y_train, y_test) = data_preprocessing(alex, params[\"PCA\"], params[\"Test-Size\"])\n(X_train, X_test, y_train, y_test, x_scaler, y_scaler) = scale_data(X_train, X_test, y_train, y_test)\n(lower_bound, upper_bound, means_preds) = get_ci(X_train, X_test, y_train, y_test, params, future_data_pca)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T22:25:06.977915Z","iopub.execute_input":"2025-03-21T22:25:06.979313Z","iopub.status.idle":"2025-03-21T22:25:41.482646Z","shell.execute_reply.started":"2025-03-21T22:25:06.979246Z","shell.execute_reply":"2025-03-21T22:25:41.481423Z"}},"outputs":[],"execution_count":142},{"cell_type":"code","source":"q_labels = list(future_data.index[-len(means_preds):])\nget_ci_chart(lower_bound, upper_bound, means_preds, alex.attrs['area'], q_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T21:51:01.957962Z","iopub.status.idle":"2025-03-21T21:51:01.958469Z","shell.execute_reply":"2025-03-21T21:51:01.958250Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"means_preds = list(means_preds)\nfor i in range(len(means_preds)):\n    print(q_labels[i] + \" => (\" + str(round(lower_bound[i], 2)) + \", \" + str(round(upper_bound[i], 2)) + \") L.E.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T21:51:01.959721Z","iopub.status.idle":"2025-03-21T21:51:01.960246Z","shell.execute_reply":"2025-03-21T21:51:01.960022Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"forecast = pd.DataFrame()\nforecast[\"Date\"] = q_labels\nforecast[\"Lower Bound\"] = lower_bound\nforecast[\"Upper Bound\"] = upper_bound\nforecast[\"Point Estimation\"] = means_preds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T21:51:01.961476Z","iopub.status.idle":"2025-03-21T21:51:01.961976Z","shell.execute_reply":"2025-03-21T21:51:01.961770Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"forecast_df_path = alex.attrs['area'] + \"-forecast\" + \".csv\" \nforecast.to_csv(forecast_df_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T21:51:01.963344Z","iopub.status.idle":"2025-03-21T21:51:01.963686Z","shell.execute_reply":"2025-03-21T21:51:01.963556Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nparams_path = alex.attrs['area'] + \"-params\" + \".json\" \nwith open(params_path, \"w\") as f:\n    json.dump(params, f, indent=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T21:51:01.964397Z","iopub.status.idle":"2025-03-21T21:51:01.964721Z","shell.execute_reply":"2025-03-21T21:51:01.964596Z"}},"outputs":[],"execution_count":null}]}